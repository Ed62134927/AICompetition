# PowerPulse æ”¹é€²ç‰ˆæƒ…æ„Ÿåˆ†æç³»çµ±
# è§£æ±ºè² é¢åè¦‹å•é¡Œ,æå‡æº–ç¢ºæ€§

import torch
import torch.nn as nn
from transformers import BertTokenizer, BertModel, BertForSequenceClassification
from transformers import pipeline
import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.cluster import KMeans
import umap
import plotly.express as px
import plotly.graph_objects as go
from typing import List, Dict, Tuple
import jieba
import re

class ImprovedABSA:
    """
    æ”¹é€²ç‰ˆæ–¹é¢ç´šæƒ…æ„Ÿåˆ†æ
    ä¿®æ­£è² é¢åè¦‹,æå‡æº–ç¢ºæ€§
    """
    
    def __init__(self, model_name='ckiplab/bert-base-chinese'):
        print("ğŸ“¥ è¼‰å…¥æ”¹é€²ç‰ˆæƒ…æ„Ÿåˆ†ææ¨¡å‹...")
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.tokenizer = BertTokenizer.from_pretrained(model_name)
        self.model = BertModel.from_pretrained(model_name).to(self.device)
        self.model.eval()
        
        # å®šç¾©ç”¢å“æ–¹é¢èˆ‡æ›´ç²¾ç¢ºçš„é—œéµè©æ¬Šé‡
        self.aspects = {
            'é‡é‡é«”ç©': {
                'keywords': ['è¼•', 'é‡', 'è–„', 'åš', 'å°', 'å¤§', 'é«”ç©', 'é‡é‡', 'å°ºå¯¸', 'ä¾¿æ”œ', 'æ”œå¸¶', 'è¼•è–„', 'è¼•å·§'],
                'positive_terms': {
                    'è¼•': 1.0, 'è–„': 1.0, 'å°': 0.8, 'ä¾¿æ”œ': 1.0, 'è¼•å·§': 1.0, 'è¢–ç': 0.9,
                    'è¿·ä½ ': 0.8, 'è¶…è–„': 1.2, 'è¶…è¼•': 1.2, 'ä¸ä½”ç©ºé–“': 1.0, 'é«”ç©å°': 0.9,
                    'é‡é‡è¼•': 1.0, 'æ‰‹æ„Ÿè¼•': 0.8, 'æ˜“æ”œ': 0.9, 'æ–¹ä¾¿æ”œå¸¶': 1.0, 'éš¨èº«': 0.8,
                    'æ”¶ç´æ–¹ä¾¿': 0.9, 'é«”ç©é©ä¸­': 0.6, 'è¼•è–„': 1.0
                },
                'negative_terms': {
                    'é‡': 0.8, 'åš': 0.8, 'å¤§': 0.6, 'ç¬¨é‡': 1.2, 'ä½”ç©ºé–“': 1.0, 'è¶…å¤§': 1.0,
                    'è¶…é‡': 1.2, 'è¶…åš': 1.0, 'æ”œå¸¶ä¸ä¾¿': 1.0, 'é›£æ”œ': 0.9, 'é«”ç©å¤§': 0.8,
                    'é‡é‡é‡': 0.9, 'æ‰‹æ„Ÿé‡': 0.7, 'æ”¶ç´å›°é›£': 0.9, 'ä¸æ–¹ä¾¿æ”œå¸¶': 1.0
                }
            },
            'å……é›»é€Ÿåº¦': {
                'keywords': ['å¿«å……', 'æ…¢', 'å¿«', 'é€Ÿåº¦', 'å……é›»', 'PD', 'QC', 'ç“¦æ•¸', 'W', 'å¿«é€Ÿ', 'é–ƒå……'],
                'positive_terms': {
                    'å¿«': 0.9, 'å¿«é€Ÿ': 1.0, 'æ€¥é€Ÿ': 1.1, 'ç§’å……': 1.2, 'é–ƒå……': 1.1, 'å……é›»å¿«': 1.0,
                    'å……é›»å¾ˆå¿«': 1.1, 'å……é›»è¶…å¿«': 1.2, 'å……é›»è¿…é€Ÿ': 1.0, 'å……é›»ä¸ç”¨ç­‰': 1.0,
                    'å¿«å……': 1.0, 'å¿«å……æ”¯æ´': 0.9, 'æ¥µé€Ÿå……é›»': 1.2, 'è¶…å¿«å……': 1.2, 'çµ¦åŠ›': 0.8
                },
                'negative_terms': {
                    'æ…¢': 0.8, 'é¾œé€Ÿ': 1.2, 'ä¹…': 0.6, 'ç­‰å¾ˆä¹…': 1.0, 'å……é›»æ…¢': 0.9,
                    'å……é›»å¾ˆæ…¢': 1.0, 'å……é›»è¶…æ…¢': 1.1, 'å……é›»ç·©æ…¢': 0.9, 'å……é›»ç­‰å¾…': 0.7,
                    'æ…¢å……': 0.8, 'å……é›»æ‹–å»¶': 1.0, 'å……é›»ä¸ç©©': 1.0, 'å……é›»å¡é “': 1.1
                }
            },
            'æ¥å£ç›¸å®¹æ€§': {
                'keywords': ['Type-C', 'Lightning', 'USB', 'æ¥å£', 'å­”', 'ç·š', 'ç›¸å®¹', 'é€šç”¨', 'è¬ç”¨', 'å¤šå£'],
                'positive_terms': {
                    'é€šç”¨': 1.0, 'ç›¸å®¹': 1.0, 'è¬ç”¨': 1.0, 'å¤šå£': 0.9, 'é½Šå…¨': 1.0, 'æ”¯æ´': 0.8,
                    'æ”¯æ´å¤šç¨®': 1.0, 'è·¨å¹³å°': 0.9, 'é©ç”¨': 0.8, 'å…¼å®¹': 0.9, 'æ”¯æ´Type-C': 0.8,
                    'æ”¯æ´PD': 0.8, 'æ”¯æ´QC': 0.8, 'å¤šåŠŸèƒ½': 0.9, 'å…¨é¢': 0.9
                },
                'negative_terms': {
                    'ä¸ç›¸å®¹': 1.2, 'æ²’æœ‰': 0.9, 'ç¼ºå°‘': 1.0, 'åªæœ‰': 0.6, 'ä¸æ”¯æ´': 1.1,
                    'ä¸å…¼å®¹': 1.2, 'ä¸é©ç”¨': 1.0, 'æ’é ­ç¼ºå°‘': 1.0, 'ä¸æ”¯æ´Type-C': 1.0,
                    'ä¸æ”¯æ´PD': 0.9, 'å–®ä¸€': 0.7
                }
            },
            'å¤–è§€æè³ª': {
                'keywords': ['å¤–è§€', 'è³ªæ„Ÿ', 'æè³ª', 'è¨­è¨ˆ', 'é¡è‰²', 'ç¾', 'é†œ', 'å¥½çœ‹', 'å¡‘è† ', 'é‡‘å±¬'],
                'positive_terms': {
                    'è³ªæ„Ÿ': 1.0, 'é«˜ç´š': 1.1, 'ç²¾ç·»': 1.0, 'å¥½çœ‹': 0.9, 'ç¾': 1.0, 'æ™‚å°š': 0.9,
                    'æ¼‚äº®': 0.9, 'å¤§æ–¹': 0.8, 'ç°¡ç´„': 0.8, 'ç¾ä»£': 0.7, 'æœ‰è³ªæ„Ÿ': 1.0,
                    'é‡‘å±¬æ„Ÿ': 0.9, 'ç£¨ç ‚': 0.7, 'æ‰‹æ„Ÿå¥½': 0.9, 'æ‰‹æ„Ÿèˆ’é©': 0.9, 'ç´°è†©': 0.8
                },
                'negative_terms': {
                    'å»‰åƒ¹': 1.2, 'é†œ': 1.1, 'å¡‘è† æ„Ÿ': 1.0, 'ç²—ç³™': 1.0, 'æ‰‹æ„Ÿå·®': 1.0,
                    'é›£çœ‹': 1.0, 'è€æ°£': 0.9, 'æ™®é€š': 0.5, 'å–®èª¿': 0.7, 'ä¸ç¾è§€': 0.9
                }
            },
            'åƒ¹æ ¼': {
                'keywords': ['åƒ¹æ ¼', 'åƒ¹éŒ¢', 'åƒ¹å€¼', 'è²´', 'ä¾¿å®œ', 'åˆ’ç®—', 'è¶…å€¼', 'CP', 'æ€§åƒ¹æ¯”'],
                'positive_terms': {
                    'ä¾¿å®œ': 0.9, 'åˆ’ç®—': 1.0, 'è¶…å€¼': 1.1, 'å€¼å¾—': 1.0, 'CPå€¼é«˜': 1.1,
                    'å„ªæƒ ': 0.8, 'ç‰¹åƒ¹': 0.7, 'æ€§åƒ¹æ¯”é«˜': 1.1, 'åƒ¹æ ¼åˆç†': 0.9, 'åƒ¹æ ¼è¦ªæ°‘': 0.9,
                    'ç‰©è¶…æ‰€å€¼': 1.1, 'ç‰©æœ‰æ‰€å€¼': 0.9, 'å¹³åƒ¹': 0.8, 'å¯¦æƒ ': 0.9
                },
                'negative_terms': {
                    'è²´': 0.8, 'æ˜‚è²´': 1.0, 'ä¸å€¼': 1.1, 'CPå€¼ä½': 1.1, 'å‘éŒ¢': 1.3,
                    'åƒ¹æ ¼åé«˜': 0.9, 'åƒ¹æ ¼éé«˜': 1.0, 'å¤ªè²´': 1.0, 'ä¸åˆ’ç®—': 1.0, 'å¤ªé«˜': 0.8
                }
            }
        }
        
        # ä½¿ç”¨å¤šå€‹æƒ…æ„Ÿåˆ†é¡å™¨é€²è¡Œé›†æˆ
        self.sentiment_classifiers = []
        try:
            # ä¸­æ–‡æƒ…æ„Ÿåˆ†é¡å™¨1
            self.sentiment_classifiers.append(
                pipeline('sentiment-analysis', 
                        model='uer/roberta-base-finetuned-jd-binary-chinese',
                        device=0 if torch.cuda.is_available() else -1)
            )
        except:
            print("è­¦å‘Š: ä¸»è¦æƒ…æ„Ÿåˆ†é¡å™¨è¼‰å…¥å¤±æ•—")
        
        # æƒ…æ„Ÿè©å…¸
        self.load_sentiment_lexicon()
    
    def load_sentiment_lexicon(self):
        """è¼‰å…¥ä¸­æ–‡æƒ…æ„Ÿè©å…¸"""
        self.positive_words = set([
            'å¥½', 'æ£’', 'è®š', 'å„ª', 'ä½³', 'å¦™', 'æ£’', 'è´Š', 'å¾ˆæ£’', 'éå¸¸å¥½', 'è¶…æ£’',
            'ä¸éŒ¯', 'æ»¿æ„', 'å–œæ­¡', 'æ¨è–¦', 'å€¼å¾—', 'å®Œç¾', 'å„ªç§€', 'å‡ºè‰²', 'å“è¶Š',
            'çµ¦åŠ›', 'å¯¦ç”¨', 'æ–¹ä¾¿', 'èˆ’æœ', 'èˆ’é©', 'é †æš¢', 'æµæš¢', 'ç©©å®š'
        ])
        
        self.negative_words = set([
            'å·®', 'çˆ›', 'ç³Ÿ', 'å£', 'åŠ£', 'åƒåœ¾', 'å¤±æœ›', 'å¾Œæ‚”', 'ä¸å¥½', 'å¾ˆå·®',
            'ä¸æ»¿', 'è¨å­', 'é›£ç”¨', 'ä¸æ¨è–¦', 'ä¸å€¼', 'ç¼ºé»', 'å•é¡Œ', 'æ•…éšœ',
            'æå£', 'ç ´', 'æ–·', 'å£æ‰', 'ä¸ç©©', 'å¡é “', 'å»¶é²', 'æ¼', 'æ¼é›»'
        ])
        
        self.negation_words = set(['ä¸', 'æ²’', 'ç„¡', 'é', 'æœª', 'åˆ¥', 'è«', 'å‹¿'])
    
    def _ensure_text(self, text) -> str:
        """ç¢ºä¿è¼¸å…¥æ˜¯å­—ä¸²"""
        if pd.isna(text):
            return ''
        return str(text) if not isinstance(text, str) else text
    
    def analyze_with_lexicon(self, text: str) -> float:
        """åŸºæ–¼è©å…¸çš„æƒ…æ„Ÿåˆ†æ(è¼”åŠ©æ–¹æ³•)"""
        words = list(jieba.cut(text))
        
        pos_count = 0
        neg_count = 0
        
        for i, word in enumerate(words):
            # æª¢æŸ¥å¦å®šè©
            is_negated = i > 0 and words[i-1] in self.negation_words
            
            if word in self.positive_words:
                if is_negated:
                    neg_count += 1
                else:
                    pos_count += 1
            elif word in self.negative_words:
                if is_negated:
                    pos_count += 1
                else:
                    neg_count += 1
        
        total = pos_count + neg_count
        if total == 0:
            return 0.0
        
        return (pos_count - neg_count) / total
    
    def calculate_aspect_score(self, text: str, aspect_info: Dict) -> float:
        """
        è¨ˆç®—æ–¹é¢æƒ…æ„Ÿåˆ†æ•¸(æ”¹é€²ç‰ˆ)
        ä½¿ç”¨å¤šç¨®æ–¹æ³•çš„åŠ æ¬Šå¹³å‡
        """
        scores = []
        weights = []
        
        # æ–¹æ³•1: åŸºæ–¼è©å…¸çš„é—œéµè©åŒ¹é…(æ¬Šé‡è¼ƒé«˜)
        pos_score = 0
        neg_score = 0
        
        for term, weight in aspect_info['positive_terms'].items():
            count = text.count(term)
            pos_score += count * weight
        
        for term, weight in aspect_info['negative_terms'].items():
            count = text.count(term)
            neg_score += count * weight
        
        # æª¢æŸ¥å¦å®šè©
        negation_pattern = r'(ä¸|æ²’|ç„¡)' + r'(' + '|'.join(aspect_info['positive_terms'].keys()) + r')'
        negation_matches = len(re.findall(negation_pattern, text))
        
        # èª¿æ•´åˆ†æ•¸
        pos_score -= negation_matches * 0.8
        neg_score += negation_matches * 0.8
        
        total = pos_score + neg_score
        if total > 0:
            keyword_score = (pos_score - neg_score) / total
            scores.append(keyword_score)
            weights.append(0.6)  # é—œéµè©åŒ¹é…æ¬Šé‡60%
        
        # æ–¹æ³•2: é€šç”¨è©å…¸æƒ…æ„Ÿåˆ†æ
        lexicon_score = self.analyze_with_lexicon(text)
        if abs(lexicon_score) > 0.1:
            scores.append(lexicon_score)
            weights.append(0.2)  # é€šç”¨è©å…¸æ¬Šé‡20%
        
        # æ–¹æ³•3: é è¨“ç·´æ¨¡å‹(å¦‚æœå¯ç”¨)
        if self.sentiment_classifiers:
            try:
                result = self.sentiment_classifiers[0](text[:512])[0]
                model_score = result['score'] if result['label'] == 'positive' else -result['score']
                scores.append(model_score)
                weights.append(0.2)  # æ¨¡å‹æ¬Šé‡20%
            except:
                pass
        
        # åŠ æ¬Šå¹³å‡
        if not scores:
            return 0.0
        
        weights = np.array(weights)
        weights = weights / weights.sum()  # æ­¸ä¸€åŒ–
        
        final_score = np.average(scores, weights=weights)
        
        # å¹³æ»‘è™•ç†,é¿å…æ¥µç«¯å€¼
        final_score = np.tanh(final_score * 1.5)  # ä½¿ç”¨tanhå£“ç¸®åˆ°[-1,1]
        
        return float(final_score)
    
    def extract_aspect_mentions(self, text: str) -> Dict[str, List[str]]:
        """æå–æ–‡æœ¬ä¸­æåŠçš„ç”¢å“æ–¹é¢"""
        mentions = {}
        text = self._ensure_text(text)
        
        for aspect, info in self.aspects.items():
            sentences = text.split('ã€‚')
            relevant_sentences = []
            
            for sentence in sentences:
                if any(keyword in sentence for keyword in info['keywords']):
                    relevant_sentences.append(sentence.strip())
            
            if relevant_sentences:
                mentions[aspect] = relevant_sentences
        
        return mentions
    
    def analyze_aspect_sentiment(self, text: str, aspect: str) -> Dict:
        """
        åˆ†æç‰¹å®šæ–¹é¢çš„æƒ…æ„Ÿ(æ”¹é€²ç‰ˆ)
        """
        aspect_info = self.aspects.get(aspect)
        if not aspect_info:
            return None
        
        text = self._ensure_text(text)
        
        # æå–ç›¸é—œå¥å­
        sentences = text.split('ã€‚')
        relevant_sentences = [
            s for s in sentences 
            if any(keyword in s for keyword in aspect_info['keywords'])
        ]
        
        if not relevant_sentences:
            return {
                'mentioned': False,
                'sentiment': 'neutral',
                'score': 0.0,
                'confidence': 0.0,
                'evidence': []
            }
        
        combined_text = 'ã€‚'.join(relevant_sentences)
        
        # ä½¿ç”¨æ”¹é€²çš„è©•åˆ†æ–¹æ³•
        score = self.calculate_aspect_score(combined_text, aspect_info)
        
        # èª¿æ•´å¾Œçš„é–¾å€¼(æ›´å°ç¨±)
        POSITIVE_THRESHOLD = 0.25
        NEGATIVE_THRESHOLD = -0.25
        
        # è¨ˆç®—ç½®ä¿¡åº¦
        confidence = min(abs(score) * 1.5, 1.0)
        
        # åˆ¤å®šæƒ…æ„Ÿé¡åˆ¥
        if score > POSITIVE_THRESHOLD:
            sentiment = 'positive'
        elif score < NEGATIVE_THRESHOLD:
            sentiment = 'negative'
        else:
            sentiment = 'neutral'
        
        return {
            'mentioned': True,
            'sentiment': sentiment,
            'score': float(score),
            'confidence': float(confidence),
            'evidence': relevant_sentences[:3],
            'pos_mentions': sum(combined_text.count(t) for t in aspect_info['positive_terms'].keys()),
            'neg_mentions': sum(combined_text.count(t) for t in aspect_info['negative_terms'].keys())
        }
    
    def analyze_full_review(self, text: str) -> Dict:
        """åˆ†æå®Œæ•´è©•è«–çš„æ‰€æœ‰æ–¹é¢"""
        results = {}
        
        for aspect in self.aspects.keys():
            results[aspect] = self.analyze_aspect_sentiment(text, aspect)
        
        return results
    
    def batch_analyze(self, texts: List[str], show_progress=True) -> pd.DataFrame:
        """æ‰¹æ¬¡åˆ†æå¤šç¯‡è©•è«–"""
        from tqdm import tqdm
        
        all_results = []
        
        iterator = tqdm(texts, desc="åˆ†æä¸­") if show_progress else texts
        
        for text in iterator:
            safe_text = self._ensure_text(text)
            analysis = self.analyze_full_review(safe_text)
            
            row = {'text': safe_text[:200]}
            
            for aspect, result in analysis.items():
                row[f'{aspect}_mentioned'] = result['mentioned']
                row[f'{aspect}_score'] = result['score'] if result['mentioned'] else None
                row[f'{aspect}_sentiment'] = result['sentiment'] if result['mentioned'] else None
                row[f'{aspect}_confidence'] = result['confidence'] if result['mentioned'] else None
            
            all_results.append(row)
        
        return pd.DataFrame(all_results)
    
    def get_sentiment_distribution(self, df: pd.DataFrame) -> pd.DataFrame:
        """ç²å–æƒ…æ„Ÿåˆ†ä½ˆçµ±è¨ˆ"""
        aspects = ['é‡é‡é«”ç©', 'å……é›»é€Ÿåº¦', 'æ¥å£ç›¸å®¹æ€§', 'å¤–è§€æè³ª', 'åƒ¹æ ¼']
        
        stats = []
        for aspect in aspects:
            sentiment_col = f'{aspect}_sentiment'
            score_col = f'{aspect}_score'
            
            if sentiment_col in df.columns:
                mentioned = df[f'{aspect}_mentioned'].sum()
                
                if mentioned > 0:
                    sentiment_counts = df[df[f'{aspect}_mentioned']][sentiment_col].value_counts()
                    avg_score = df[df[f'{aspect}_mentioned']][score_col].mean()
                    
                    stats.append({
                        'æ–¹é¢': aspect,
                        'æåŠæ¬¡æ•¸': mentioned,
                        'æ­£é¢': sentiment_counts.get('positive', 0),
                        'ä¸­æ€§': sentiment_counts.get('neutral', 0),
                        'è² é¢': sentiment_counts.get('negative', 0),
                        'å¹³å‡åˆ†æ•¸': round(avg_score, 3),
                        'æ­£é¢æ¯”ä¾‹': f"{sentiment_counts.get('positive', 0) / mentioned * 100:.1f}%",
                        'è² é¢æ¯”ä¾‹': f"{sentiment_counts.get('negative', 0) / mentioned * 100:.1f}%"
                    })
        
        return pd.DataFrame(stats)


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # æ¸¬è©¦æ•¸æ“š
    test_texts = [
        "é€™å€‹è¡Œå‹•é›»æºè¶…è¼•è–„,å……é›»é€Ÿåº¦å¾ˆå¿«,æ”¯æ´PDå¿«å……,è³ªæ„Ÿä¹Ÿä¸éŒ¯,åƒ¹æ ¼åˆç†",
        "å……é›»å¯¶å¤ªé‡äº†,è€Œä¸”å……é›»å¾ˆæ…¢,ä¸æ”¯æ´Type-Cå¾ˆä¸æ–¹ä¾¿",
        "GaNæŠ€è¡“çœŸçš„ä¸éŒ¯,å……é›»è¶…å¿«,å°±æ˜¯åƒ¹æ ¼æœ‰é»è²´",
        "é€™æ¬¾å°¿è¢‹å¾ˆè¼•ä¾¿,ä½†å®¹é‡å¤ªå°äº†,å¤–è§€è¨­è¨ˆå¾ˆç¾",
        "é‡é‡é‚„å¯ä»¥,å……é›»é€Ÿåº¦æ­£å¸¸,æ¥å£é½Šå…¨å¾ˆæ–¹ä¾¿,å¤–è§€ä¸€èˆ¬èˆ¬,åƒ¹æ ¼åé«˜",
        "ç”¢å“å¾ˆå¥½ç”¨,è³ªæ„Ÿä¸éŒ¯,å……é›»ä¹ŸæŒºå¿«çš„,è¼•å·§æ–¹ä¾¿æ”œå¸¶",
        "é‚„è¡Œå§,æ²’ä»€éº¼ç‰¹åˆ¥çš„,å……é›»é€Ÿåº¦æ™®é€š,å¤–è§€ä¹Ÿæ™®é€š",
        "å……é›»ä¸å¿«ä½†ä¹Ÿä¸ç®—æ…¢,é‡é‡é©ä¸­,è³ªæ„Ÿé‚„å¯ä»¥"
    ]
    data = pd.read_csv('./AICompetition/crawlers_result/data_mobile.csv')
    data1=list(data['title'])
    data2=list(data['comments'])
    data3=data1+data2
    data3=[x for x in data3 if str(x).lower() not in ('nan', 'none')]
    
    print("ğŸš€ åˆå§‹åŒ–æ”¹é€²ç‰ˆæƒ…æ„Ÿåˆ†æç³»çµ±...")
    analyzer = ImprovedABSA()
    
    print("\nğŸ“Š åŸ·è¡Œæ‰¹æ¬¡åˆ†æ...")
    results_df = analyzer.batch_analyze(data3)
    
    print("\nğŸ“ˆ æƒ…æ„Ÿåˆ†ä½ˆçµ±è¨ˆ:")
    stats_df = analyzer.get_sentiment_distribution(results_df)
    print(stats_df.to_string(index=False))
    
    print("\nğŸ’¾ ä¿å­˜çµæœ...")
    results_df.to_csv('improved_absa_results.csv', index=False, encoding='utf-8-sig')
    stats_df.to_csv('sentiment_distribution.csv', index=False, encoding='utf-8-sig')
    
    print("\nâœ… åˆ†æå®Œæˆ!")
    
    # é¡¯ç¤ºéƒ¨åˆ†è©³ç´°çµæœ
    print("\nğŸ“‹ éƒ¨åˆ†è©³ç´°çµæœ:")
    for idx, row in results_df.head(3).iterrows():
        print(f"\næ–‡æœ¬ {idx+1}: {row['text']}")
        print("å„æ–¹é¢æƒ…æ„Ÿ:")
        for aspect in ['é‡é‡é«”ç©', 'å……é›»é€Ÿåº¦', 'åƒ¹æ ¼']:
            if row[f'{aspect}_mentioned']:
                print(f"  - {aspect}: {row[f'{aspect}_sentiment']} ({row[f'{aspect}_score']:.2f})")
